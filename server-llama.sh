cd ../llama-cpp
./server -m ../llama-models/7B-chat/ggml-model-q4_0.gguf -c 2048 